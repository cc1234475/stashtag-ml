{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.all import *\n",
    "from fastai.vision.all import *\n",
    "import timm\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the data loader the read in the images.\n",
    "\n",
    "Within the `images` folder it should have subfolders for each tag.\n",
    "if a image has multiple tags it should have a comma separator in the folder name.\n",
    "\n",
    "example:\n",
    "- dog,foxhound/image.jpg\n",
    "- dog,bulldog/image.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parent_labels(o):\n",
    "    \"Label `item` with the parent folder name.\"\n",
    "    return Path(o).parent.name.split(\",\")\n",
    "\n",
    "batch_tfms = aug_transforms(max_lighting=0.1, size=224)\n",
    "dls = DataBlock(\n",
    "    blocks=(ImageBlock, MultiCategoryBlock), \n",
    "    get_items=get_image_files, \n",
    "    splitter=RandomSplitter(valid_pct=0.2),\n",
    "    get_y=parent_labels,\n",
    "    item_tfms=[Resize(224, method='squish')],\n",
    "    batch_tfms=batch_tfms\n",
    ").dataloaders(\"images\", bs=256)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values that help with with training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingBCEWithLogitsLossFlat(BCEWithLogitsLossFlat):\n",
    "    def __init__(self, eps:float=0.1, **kwargs):\n",
    "        self.eps = eps\n",
    "        super().__init__(thresh=0.2, **kwargs)\n",
    "    \n",
    "    def __call__(self, inp, targ, **kwargs):\n",
    "        # https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/166833#929222\n",
    "        targ_smooth = targ.float() * (1. - self.eps) + 0.5 * self.eps\n",
    "        return super().__call__(inp, targ_smooth, **kwargs)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"FlattenedLoss of LabelSmoothingBCEWithLogits()\"\n",
    "    \n",
    "metrics=[FBetaMulti(2.0, 0.2, average='samples'), partial(accuracy_multi, thresh=0.95)]\n",
    "wd      = 5e-7 #weight decay parameter\n",
    "opt_func = partial(ranger, wd=wd)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the vision learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, \"vit_base_patch32_224\", metrics=metrics, loss_func=LabelSmoothingBCEWithLogitsLossFlat(), opt_func=opt_func).to_fp16()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model, takes about 30 min on a RTX 3060 with 17.000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save a snapshot in case we want to load it in later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('vit_base_patch16_224-50')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the model, this can be used with https://huggingface.co/spaces/cc1234/stashtag/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(\"models.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leanr_int = ClassificationInterpretation.from_learner(learn)\n",
    "# leanr_int.plot_confusion_matrix()\n",
    "leanr_int.plot_top_losses(6, nrows=2)\n",
    "# leanr_int.print_classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the result. \n",
    "!import will use linux screenshot tool to take a screengrab but otherwise you can just pass in a file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !import dd.jpg\n",
    "a = \"dd.jpg\"\n",
    "image = PILImage.create(a)\n",
    "tags,x,y = learn.predict(image)\n",
    "print(f\"Tags are: {tags}.\")\n",
    "for i, s in enumerate(x):\n",
    "    if s:\n",
    "        print(y[i])\n",
    "\n",
    "image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "15777b7ea11de2d51c8446a4c89ee04804ebf458a0efd75219ce18b324abffec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
